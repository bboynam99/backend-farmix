import {
  Inject,
  Injectable,
  Logger,
  OnApplicationShutdown,
} from '@nestjs/common';
import { ConfigType } from '@nestjs/config';
import { Cron } from '@nestjs/schedule';
import IORedis from 'ioredis';
import { StakingPoolsNftCollectionsRepo } from './repos/staking-pools-nft-collections.repo';
import { StakingPoolRepo } from './repos/staking-pools.repo';
import { StakingPoolNftCollectionSyncService } from './staking-pool-nft-collection-sync.service';
import { StakingPoolSyncService } from './staking-pool-sync.service';
import { SIX_MONTHS_IN_SEC } from '../../common';
import { StakingPoolDescriptor, StakingPoolNftCollectionDescriptor } from '../../common/types';
import { blockchainSyncConfig, MAIN_REDIS } from '../../config';
import { DistributedTaskRunner } from '../../shared/redis';

/**
 * The scheduler is responsibility is to instantiate blockchain scraping jobs.
 * The scraping process is designed with the following principles:
 *  * scalable and distributed - basically one unit of work of scraping is parsing a specific address.
 *    Only one instance of app can scrape transactions of single address,
 *    but if there is multiple addresses to scrape this addresses will be destructed across all instances.
 *    (This is backboned by redis and redlock algorithm which also allows to use redis clusters)
 *
 *  * graceful shutdown - if app is closing due to update or critical errors the special signals will be send to handlers
 *    and then handlers return will be awaited, this will at minimum prevent data inconsistency
 *
 *  * timers - all jobs is scheduled periodically in interval or cron fashion
 *
 * TYPES OF SCRAPES JOBS:
 *  * staking pool scrape - Scrape transactions from staking pool. The pools descriptors is configurable constants and maintained by app admins
 *
 *  * staking pool nft collections scape - Scrape nft collection of staking pools.
 *    The staking pools nft collections is generated by staking pools and has lifecycles.
 *    From some point of time the nfts collection become unused and will never again accept transactions, this nft collection will not be scraped.
 *    This is handlers responsible to determine nft collection lifecycle ends and mark it as processed.
 *    NOTE: nft collection detected in pool scrape handlers,
 *          so the collection will no be processed until pool scrape job ends, collection is detected and next scheduler round inited
 */
@Injectable()
export class BlockchainSyncScheduler implements OnApplicationShutdown {
  private logger = new Logger(BlockchainSyncScheduler.name);
  private distributedTaskRunner: DistributedTaskRunner;

  constructor(
    @Inject(MAIN_REDIS) private redis: IORedis,
    @Inject(blockchainSyncConfig.KEY) private syncConf: ConfigType<typeof blockchainSyncConfig>,
    private stakingPoolRepo: StakingPoolRepo,
    private stakingPoolNftCollectionRepo: StakingPoolsNftCollectionsRepo,
    private stakingPoolSyncService: StakingPoolSyncService,
    private stakingPoolNftCollectionSyncService: StakingPoolNftCollectionSyncService,
  ) {
    this.distributedTaskRunner = new DistributedTaskRunner(
      'blockchainSync',
      this.redis,
    );
  }

  async onApplicationShutdown(): Promise<void> {
    await this.distributedTaskRunner.stop();
  }

  @Cron('*/5 * * * * *') // every second by on machine clock basis
  async syncAllStakingPools(): Promise<void> {
    const activePools = await this.stakingPoolRepo.getAllActive();
    await Promise.all(activePools.map(async (p) => this.syncStakingPool(p)));
  }

  @Cron('*/5 * * * * *') // every second by on machine clock basis
  async syncAllStakingPoolNftCollections(): Promise<void> {
    const activeCollections = await this.stakingPoolNftCollectionRepo.getAllActive();
    await Promise.all(activeCollections.map(async (c) => this.syncStakingPoolNftCollection(c)));
  }

  async syncStakingPool(pool: StakingPoolDescriptor): Promise<void> {
    const key = `staking_pool:${pool.id}`;
    const shouldRun = async () => this.shouldSync(key, this.syncConf.stakingPoolsSyncIntervSec);
    const taskCb = async (signal: AbortSignal) => {
      await this.stakingPoolSyncService.sync(pool, signal);
      await this.setSyncedAt(key);
    };

    try {
      await this.distributedTaskRunner.runOnce(
        key,
        taskCb,
        { retryCount: 0, shouldRun },
      ).catch((err) => {
        if (this.distributedTaskRunner.isLockedByAnotherServiceErr(err)) {
          return;
        }
        throw err;
      });

    } catch (err) {
      this.logger.error({ err, pool }, 'unexpected error occur during staking pool sync');
    }
  }

  async syncStakingPoolNftCollection(collection: StakingPoolNftCollectionDescriptor): Promise<void> {
    const key = `staking_pool_nft_collection:${collection.id}`;
    const shouldRun = async () => this.shouldSync(key, this.syncConf.stakingPoolsNftCollectionsSyncIntervSec);
    const taskCb = async (signal: AbortSignal) => {
      await this.stakingPoolNftCollectionSyncService.sync(collection, signal);
      await this.setSyncedAt(key);
    };

    try {
      await this.distributedTaskRunner.runOnce(
        key,
        taskCb,
        { retryCount: 0, shouldRun },
      ).catch((err) => {
        if (this.distributedTaskRunner.isLockedByAnotherServiceErr(err)) {
          return;
        }
        throw err;
      });

    } catch (err) {
      this.logger.error({ err, collection }, 'unexpected error occur during staking pool nft collection sync');
    }
  }

  private async shouldSync(key: string, intervalSec: number): Promise<boolean> {
    const lastSyncKey = `${key}:last_sync_at`;
    const lastSyncAt = await this.redis.get(lastSyncKey);

    if ((new Date(lastSyncAt ?? 0).valueOf() + (intervalSec * 1000)) > Date.now()) {
      return false;
    }

    return true;
  }

  private async setSyncedAt(key: string): Promise<void> {
    const lastSyncKey = `${key}:last_sync_at`;

    await this.redis.set(lastSyncKey, new Date().toISOString(), 'EX', SIX_MONTHS_IN_SEC);
  }
}